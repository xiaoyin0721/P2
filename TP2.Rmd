---
title: "P2"
author: "Tobias Pedersen, Dat Luong, Adam Rumi, Kristoffer Lading, Xiaoyin Chang, Kasper Sommer"
date: "4/3/2022"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(mosaic)
```


# Introduktion
I denne del af projektet, skabes der en Pseudo-Random Number generator, hvis formål er at generere tilfældige tal. Fordelingen af disse tal vil være uniform, og ved hjælp af en Box-Muller transformation vil der opnås en normalfordeling. Grunden til dette er at undersøge stikprøver fra en normalfordeling i forhold til Central Limit Theorem, da der er adskillige interessante statistiske spørgsmål herinden under.


# Pseudo-Random Number Generators
For at kunne generere tilfældige tal ud fra deterministiske computere,er det nødvendigt at bearbejde et input ved hjælp af en algoritme, således at det genererede tal tilsyneladende er tilfældigt. Et sådanne genereret tal kaldes et "Pseudo-Random Number", og disse bliver genereret ved hjælp af Pseudo-Random Number Generators (også kaldet PRNG'er). PRNG'er benytter et seed, som kan bestemmes af brugeren, til at generere de tilfældige tal. Et eksempel på en kendt PRNG, er en Lineære Kongruentiel Generator (Også kaldet LCG). 

# True-Random Number Generators
I modsætning til PRNG'er, eksisterer der også True-Random Number Generators (også kaldet TRNG'er). Disse generators genererer tilfældige tal, uden nødvendigvis at afhænge af algoritmer. Et eksempel på en kendt TRNG, er at generere tilfældige tal ved hjælp af atmosfærisk støj.

# Sammenligning af PRNG'er og TRNG'er

En PRNG er meget velegnet til simulationer, da det er muligt at reproducere dataet ved at sætte seed'et til en bestemt værdi. Dette gør det muligt for andre indenfor samme område, at kunne få dataet fra en given simulation, og derved er det nemmere at diskutere fund og eller problemer med den givne simulation.

TRNG'er kan også benyttes til simulationer, og siden tallene er mere tilfældige i forhold til PRNG'erne, kan de være mere velegnet til simulationer. Problemet er dog, at siden seedets værdi ikke kan bestemme, er det umuligt at reproducere dataet. Grundet dette, er PRNG i adskillige situationer foretrukket indenfor simulationer. Dog er det værd at nævne, at siden dataet fra en TRNG ikke kan reproduceres, er det optimalt for ting som skal være tilfældige, såsom lotteriet, gambling eller kryptering.

I dette projekt vil en PRNG implementeres i R, hvornæst de uniform fordelte tal skal transformeres v.h.a. Box-Muller. Dernæst vil R's indbyggede PRNG benyttes til at undersøge adskillige statistiske spørgsmål.

# Lineær kongruens generator
I en lineær kongruens generator (LCG) er det muligt at generere tilfældige tal. LCG er en PRNG, så tallene der fås fra generatoren, vil ikke være fuldstændigt tilfældige. For LCG'en benyttes følgende formel, for at generere de tilfældige tal: 
$$
\begin{aligned}
      X_{(n+1)}=(a*X_n+c)\;mod\;m
\end{aligned}      
$$
	- $X_0$, som svarer til denne generators seed, $X_0$ $\geq$ 0.  
	- $a$, som bliver ganget på $X_0$, $a$ $\geq$ 0.  
	- $c$, som bliver adderet til $X_0$, $c$ $\geq$ 0.  
	- $m$, kaldet modulus, $m > X_0$, $m > a$, $m > c$.  

Her vil man starte med at indsætte $X_0$ på $X_{n}$'s plads, og ud fra dette kan man finde $X_1$. Derefter kan man indsætte $X_1$ på $X_n$’s plads og derefter få $X_2$. Denne proces kan gentages så mange gange som man har brug for.
Det er vigtigt at nævne, at før eller siden vil tallene fra sådanne en generator begynde at gentage sig selv, længden fra det første tal i generatoren frem til det første gentagende tal kaldes for en periode, og perioden afhænger meget af de valgte værdier af $a$, $c$ og $m$. Ved at ændre m til et meget højt tal, vil der dog gå meget lang tid før at tallene begynder at gentage sig selv. Andre der bruger denne generator anbefaler $2^{31}$. 
De tilfældige tal man kan få ud af denne generator, er uniform fordelt. Tallene er kontinuære. Ved at omhyggeligt vælge sine $a, c$ og $m$ værdier kan man også sørge for at tallene man får, ikke ser ud til at have nogen korrelation med hinanden. GØR DET HER TOBIAS!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!! 

![](C:/Users/tobop/OneDrive - Aalborg Universitet/Documents/GitHub/P2/PRNG_Forklaring.jpg){width=50%}

Når ens program startes op får man en state ud fra det seed man bruger. Denne state kan dernæst ændres til en anden state ved hjælp af en funktion f, som ikke har en invers funktion. Dette kan dog kun gøres en gang per tilstand, hvorimod andre PRNG’er kan have flere tilstande på en gang. Et eksempel er Mersenne twister, men denne vil ikke gennemgås i rapporten.

# Implementering af linear congruential generator
Nedenstående blok kode blev brugt til at lave den lineære kongruentiale generator (LCG):
```{r}

linear_congruence <- function(i, X_0) {
t <- 0
a <- 11102357
c <- 21353
m <- 2**32
v1 <- c()
while(t < i){
  X_0 <- (a*X_0+c)%%m
  v1 <- c(v1 , as.numeric(((X_0)/m)))
  t <- t + 1
}
return(v1)
}
linear_congruence(i=10, X_0 = 234)
```

Som beskrevet i afsnittet om LCG'er, skal generatoren bruge et seed. Derfor sættes $X_0$ lig med et tilfældigt tal, som i dette tilfælde er $1576$. Der skulle også bruges en $a$, $c$ og $m$ værdi, som i denne kode er sat til henholdsvis $11,102,357$, $21,353$ og $2^{32}$. Der er også oprettet to variabler: $t$ og $i$, som bruges i programmet, hvor $i$ er en parameter for funktionen, som svarer til det ønskede antal tilfældigt genererede tal, og $t$ har en startsværdi på 0, og øges med 1, hvert gang et tilfældigt tal genereres. Funktionen er sat op således, at så længe $t$ er mindre end $i$, vil $X_0$ blive brugt til at udregne en ny $X_0$ værdi. Værdien bliver dernæst tilføjet til en vektor $v1$, dog ikke før at værdien bliver divideret med $m$ og ganget med 100. Dernæst bliver $1$ adderet til $t$, og så loop'er funktionen. Resultatet af denne funktion, kan ses forneden:  


```{r Linear Congruence, echo=FALSE}

gf_histogram(~linear_congruence(i=100000, X_0 = 1576), breaks = seq(0, 1, by=0.1), fill="black", col="grey", xlim = c(0, 1), ylab = "Antal", xlab = "Tilfældige tal inddelt i intervaller", title = "Resultaterne af den implementerede PRNG")
    
```

# Box-Muller transformation
Box-Muller transformationen er en metode, hvori to uniforme random variabler transformeres til et par uafhængige standard normal random variabler. Den primære ide er at ændre koordinatorne fra kartetiske til polære koordinator.
Sammenhænget mellem kartetiske og polære-koordinator er:
$x = cos(\theta)*r$
$y = sin(\theta)*r$
Ifølge Box-Muller erstattes $\theta$ med $2\pi*U_2$. Dette svarer til at generere en tilfældig vinkel mellem 0 og 2 pi. Yderligere erstattes $r$ med $\sqrt V$
hvor $V$ er $-2*ln*U_1$. Dette svarer til at generere en tilfældig radius. 
Her skal der altså bruges to værdier, $U_1$ og $U_2$. Disse værdier er de uniformfordelte tilfældige tal.
Ud af dette, fås der to tal $x$ og $y$, som i dette tilfælde er uafhængige tilfældige variabler med en normalfordeling. Forneden kan resultaterne af Box-Muller transformationen ses:

```{r echo=FALSE}

Box_muller_transform <- function(){
  n <- 10^4
  samples <- matrix(ncol = 2, nrow = n)
  uni_rand_num1 <- linear_congruence(i=10000, X_0 = 145)
  uni_rand_num2 <- linear_congruence(i=10000, X_0 = 7346)
  R <- sqrt(-2*log(uni_rand_num1))
  theta <- 2*pi*uni_rand_num2
  X <- R*cos(theta)
  Y <- R*sin(theta)
  samples[,1] <- X
  samples[,2] <- Y 
  
  Label <- rep(c("x", "y"),n)
  value <- c(samples[,1],samples[,2])
  df <- data.frame(value, Label)
  library(ggplot2)
  plt <- ggplot(df, aes(x=value, color=Label, fill=Label)) + geom_histogram(aes(y=..density..), bins = 60, position= "identity", alpha =0.3) + labs(title = "X & Y efter Box-Muller transformationen", x="Value", y="Density", ) + theme_bw()
  print(plt)
}
Box_muller_transform()


```


```{r}

u1 <- runif(10^5)
u2 <- runif(10^5)

theta <- u1 * 2 * pi
v <- -2*log(u2)
r <- sqrt(v)

x <- r*cos(theta)
y <- r*sin(theta)

shapiro.test(x[1:5000])

hist(x, breaks = 50)
hist(y, breaks = 50)
?hist

plot(x,y,pch=19, cex=0.4, asp=1, las=1)


```
```{r}
#plot PDF curves
curve(dexp(x, rate = .5), from=0, to=10, col='blue')
curve(dexp(x, rate = 1), from=0, to=10, col='red', add=TRUE)
curve(dexp(x, rate = 1.5), from=0, to=10, col='purple', add=TRUE)

#add legend
legend(7, .5, legend=c("rate=.5", "rate=1", "rate=1.5"),
       col=c("blue", "red", "purple"), lty=1, cex=1.2)
```
```{r}
p <- ggplot(data.frame(x = c(-3,3)), aes(x = x)) +
  stat_function(fun = dnorm)

p +
  annotate("text", x = 2, y = 0.3, parse = TRUE,
           label = "frac(1, sqrt(2 * pi)) * e ^ {-x^2 / 2}")
```


## Box Muller 


The Box-Muller transform (George Box and Mervin Muller, 1958) is a method to transform two uniform random variables into a pair of independent standard normal random variables. The main idea is to change coordinates from Cartesian to polar coordinates.




Input: 
  $U_{i}$: $\Omega \to (0,1) ,(i = 1, 2) $
  
  Output:$(\Omega, F, P)$, probability space


#Probability density function of X and Y 
X, Y are standard normal (standard Gaussian) random variables, shown as $X, Y \sim {\sf N(0,1)}$, X and Y are independent variables.

A continuous random variable Z is said to be a standard normal (standard Gaussian) random variable, shown as $X∼N(0,1)$, if its PDF is given by

$f_X(x)=1/ \sqrt{2\pi} \exp{(−x^2)/2}$ for all $z∈R$
  
  ```{r}
p <- ggplot(data.frame(x = c(-3,3)), aes(x = x)) +
  stat_function(fun = dnorm)

p +
  annotate("text", x = 2, y = 0.3, parse = TRUE,
           label = "frac(1, sqrt(2 * pi)) * e ^ {-x^2 / 2}")
```



#Joint Probability Density function of X, Y 

The joint probability Density function (PDF) of two random variables will form a normal distribution, will prove that how X and Y can be sampled from two uniform random distributions to form a joint normal distribution.

The joint Probability Density Function (også kaldet PDF) tager to uniform variabler og former en normal fordeling


#Transform to polar coordiantes, Jacobian Matrix 

The key idea is to transform the joint PDF from a function of x, y to a function of R, $\theta$. $f_XY(x,y) = f(x)f(y) = 1/2\pi\exp{-(x^2+y^2)/2}$ Transforming to polar cooridnates
$f_XY(x,y)dxdy= f_R\theta(r,\theta)rdrd\theta$
  
  The relationship between Cartesian coordinates(x,y)and polar coordinates(r, $\theta$) is 

$x = cos(\theta)r$
  $y = sin(\theta)r$
  
  $f_R\theta(r,\theta)rdrd\theta = f_XY(x,y)dxdy/drd\theta =  f_XY(x,y)|d(x,y)/d(r,\theta)|$
  
  $|d(x,y)/d(r,\theta)|$ is Jacobian matrix, which can be resolved as r


#Rewrite the R, $\theta$ function

Using substitution method, the $r, \theta$ function is transformed to pdf in terms of $r^2, \theta$
  
  
  $\int_0^2\pi  \int_0^\infty (1/2\pi) \mathrm{e}^{-r^2/2} r\mathrm{d}r\mathrm{d}\theta$
  
  $1/2\mathrm{d}r^2 = r\mathrm{d}r$ 
  
  It is transformed to $(1/2e^(-r^2/2) \mathrm{d}r^2) 1/2\pi\mathrm{d}\theta$
  It can be seen as joint function of r^2 and theta

Therefore, we just need to sample values from a uniform random distribution and multiply with 2\pi for \theta values $(U1 \sim{(0, 2\pi)})$, and sample from a exponential distribution (\lamda = 1/2) for r^2 values, then R can be computed by $r = \sqrt(V)$
  
  
  
  #Exponential funktion
  
  
  
  For an exponential distribution, 
$f(x) = \lambda e^(-\lambda x)$
  
  The cumulative probability function(cdf) of exponential distribution is given as 

$\int_\infty^0 \lambda e^(-\lambda x)$
  
  By applying inverse transformtion, the value of $R^2$ can be 
sampled as $-2log(U2) \sim{Exp(\lambda = 1/2 )}$ 
  
  Then the joint pdf of X, Y can be expressed in polar coordinates by

$x = cos(\theta)r$
$y = sin(\theta)r$




# Teori

## Middelværdi og standardafvigelse

## Fordelinger

## CLT

## Statistisk inferens

### Estimation

### Konfidens Interval


